{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5f1cf4f",
   "metadata": {},
   "source": [
    "## 1) Execution Summary\n",
    "\n",
    "This report documents a churn-prediction BI workflow implemented in Streamlit and reproduced here for reproducibility.\n",
    "\n",
    "**Scope**\n",
    "\n",
    "- Dataset A: **Telco churn** (`telco_customer_churn.csv`) — target column: `Churn`.\n",
    "- Dataset B: **Bank churn** (`churn.csv`) — target column: `Exited`.\n",
    "\n",
    "**What was done**\n",
    "\n",
    "- Loaded and profiled both datasets (schema, missingness, class balance).\n",
    "- Applied preprocessing + feature engineering consistent with the Streamlit app.\n",
    "- Trained and compared four classification models on each dataset: SVM, Logistic Regression, Random Forest, Gradient Boosting.\n",
    "- Reported performance using accuracy, precision, recall, F1, confusion matrices, and ROC-AUC.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60cc27d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_curve,\n",
    "    auc,\n",
    ")\n",
    "\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e78947",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "telco_path = 'telco_customer_churn.csv'\n",
    "bank_path = 'churn.csv'\n",
    "\n",
    "telco_raw = pd.read_csv(telco_path)\n",
    "bank_raw = pd.read_csv(bank_path)\n",
    "\n",
    "telco_raw.shape, bank_raw.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4200a2c8",
   "metadata": {},
   "source": [
    "## 2) Comparison of Datasets\n",
    "\n",
    "This section compares: size, schema, feature types, missing values, duplicates, and target distributions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de02733",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_profile(df: pd.DataFrame, target: str):\n",
    "    out = {}\n",
    "    out['rows'] = df.shape[0]\n",
    "    out['cols'] = df.shape[1]\n",
    "    out['object_cols'] = df.select_dtypes(include=['object']).columns.tolist()\n",
    "    out['numeric_cols'] = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    out['missing_total'] = int(df.isna().sum().sum())\n",
    "    out['duplicate_rows'] = int(df.duplicated().sum())\n",
    "    if target in df.columns:\n",
    "        out['target_value_counts'] = df[target].value_counts(dropna=False).to_dict()\n",
    "    else:\n",
    "        out['target_value_counts'] = None\n",
    "    return out\n",
    "\n",
    "telco_profile = dataset_profile(telco_raw, target='Churn')\n",
    "bank_profile = dataset_profile(bank_raw, target='Exited')\n",
    "pd.DataFrame([\n",
    "    {'dataset':'Telco', **telco_profile},\n",
    "    {'dataset':'Bank', **bank_profile},\n",
    "]).set_index('dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434a7509",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values per dataset (top 15)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 4))\n",
    "\n",
    "telco_missing = telco_raw.isna().sum().sort_values(ascending=False).head(15)\n",
    "bank_missing = bank_raw.isna().sum().sort_values(ascending=False).head(15)\n",
    "\n",
    "axes[0].bar(telco_missing.index.astype(str), telco_missing.values)\n",
    "axes[0].set_title('Telco: Missing Values (Top 15)')\n",
    "axes[0].tick_params(axis='x', rotation=90)\n",
    "\n",
    "axes[1].bar(bank_missing.index.astype(str), bank_missing.values)\n",
    "axes[1].set_title('Bank: Missing Values (Top 15)')\n",
    "axes[1].tick_params(axis='x', rotation=90)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829ae81b",
   "metadata": {},
   "source": [
    "### Key Observations (fill after running)\n",
    "\n",
    "- **Telco**: _(describe class balance, missing TotalCharges handling, categorical richness, etc.)_\n",
    "- **Bank**: _(describe Geography/Gender categories, numeric-heavy schema, target imbalance, etc.)_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba3a3f6",
   "metadata": {},
   "source": [
    "## 3) Methodology and Choices\n",
    "\n",
    "### Modeling strategy\n",
    "\n",
    "- Split: train/test using `train_test_split`.\n",
    "- Models compared: SVM, Logistic Regression (scaled), Random Forest, Gradient Boosting.\n",
    "- Metrics: accuracy, precision, recall, F1, ROC-AUC + confusion matrix.\n",
    "\n",
    "### Preprocessing choices\n",
    "\n",
    "- Telco: numeric coercion for `TotalCharges`, binary encoding for Yes/No and gender, one-hot for multi-class columns.\n",
    "- Bank: drop IDs, encode Gender, one-hot Geography, feature engineering (age groups, tenure groups, credit risk, balance risk, etc.).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30aa0a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Telco preprocessing (aligned with streamlit.py)\n",
    "def preprocess_telco(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "\n",
    "    # Coerce TotalCharges -> numeric and impute median\n",
    "    if 'TotalCharges' in df.columns:\n",
    "        df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')\n",
    "        df['TotalCharges'] = df['TotalCharges'].fillna(df['TotalCharges'].median())\n",
    "\n",
    "    # Consolidate 'No internet service' -> 'No'\n",
    "    for col in df.columns:\n",
    "        try:\n",
    "            uniques = df[col].dropna().unique().tolist()\n",
    "        except Exception:\n",
    "            continue\n",
    "        if set(uniques) == set(['No internet service', 'No', 'Yes']):\n",
    "            df[col] = df[col].replace({'No internet service': 'No'})\n",
    "\n",
    "    # Consolidate 'No phone service' -> 'No'\n",
    "    for col in df.columns:\n",
    "        try:\n",
    "            uniques = df[col].dropna().unique().tolist()\n",
    "        except Exception:\n",
    "            continue\n",
    "        if set(uniques) == set(['No phone service', 'No', 'Yes']):\n",
    "            df[col] = df[col].replace({'No phone service': 'No'})\n",
    "\n",
    "    # Binary mappings\n",
    "    for col in df.columns:\n",
    "        try:\n",
    "            uniques = sorted(pd.Series(df[col].dropna().unique()).astype(str).tolist())\n",
    "        except Exception:\n",
    "            continue\n",
    "        if uniques == ['No', 'Yes']:\n",
    "            df[col] = df[col].map({'No': 0, 'Yes': 1})\n",
    "        if uniques == ['Female', 'Male']:\n",
    "            df[col] = df[col].map({'Male': 0, 'Female': 1})\n",
    "\n",
    "    # Ensure required multiclass columns exist\n",
    "    for needed in ['InternetService', 'Contract', 'PaymentMethod']:\n",
    "        if needed not in df.columns:\n",
    "            df[needed] = 'Unknown'\n",
    "\n",
    "    dummies = pd.get_dummies(\n",
    "        df,\n",
    "        dtype=int,\n",
    "        columns=['InternetService', 'Contract', 'PaymentMethod'],\n",
    "        drop_first=True,\n",
    "    )\n",
    "\n",
    "    if 'Churn' in dummies.columns and not is_numeric_dtype(dummies['Churn']):\n",
    "        if dummies['Churn'].dtype == object:\n",
    "            dummies['Churn'] = dummies['Churn'].map({'No': 0, 'Yes': 1})\n",
    "\n",
    "    return dummies\n",
    "\n",
    "telco = preprocess_telco(telco_raw)\n",
    "telco.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6edbc40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bank preprocessing + feature engineering (aligned with your notebook + streamlit.py additions)\n",
    "def preprocess_bank(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "\n",
    "    # Drop identifiers\n",
    "    df = df.drop(columns=[c for c in ['RowNumber', 'CustomerId', 'Surname'] if c in df.columns])\n",
    "\n",
    "    # Fill missing values\n",
    "    for col in df.columns:\n",
    "        if col == 'Exited':\n",
    "            continue\n",
    "        if is_numeric_dtype(df[col]):\n",
    "            df[col] = df[col].fillna(df[col].median())\n",
    "        else:\n",
    "            df[col] = df[col].fillna('Unknown')\n",
    "\n",
    "    # Gender\n",
    "    if 'Gender' in df.columns:\n",
    "        df['Gender'] = df['Gender'].map({'Male': 1, 'Female': 0}).fillna(0).astype(int)\n",
    "\n",
    "    # Geography one-hot\n",
    "    if 'Geography' in df.columns:\n",
    "        geo_dummies = pd.get_dummies(df['Geography'], drop_first=True, dtype=int)\n",
    "        df = pd.concat([df.drop(columns=['Geography']), geo_dummies], axis=1)\n",
    "\n",
    "    # Feature engineering\n",
    "    if 'Balance' in df.columns and 'EstimatedSalary' in df.columns:\n",
    "        df['Balance_to_Salary_Ratio'] = df['Balance'] / (df['EstimatedSalary'] + 1)\n",
    "        df['Is_Wealthy'] = (df['Balance'] > df['Balance'].quantile(0.75)).astype(int)\n",
    "\n",
    "    if 'Age' in df.columns:\n",
    "        age_group = pd.cut(df['Age'], bins=[0, 30, 40, 50, 60, 100], labels=['18-30', '31-40', '41-50', '51-60', '60+'])\n",
    "        df['Age_Group'] = pd.Categorical(age_group).codes\n",
    "        df['Is_Senior'] = (df['Age'] > 60).astype(int)\n",
    "\n",
    "    if 'Tenure' in df.columns:\n",
    "        tenure_group = pd.cut(df['Tenure'], bins=[0, 1, 3, 5, 10, float('inf')], labels=['New', 'Developing', 'Mature', 'Loyal', 'Very_Loyal'], include_lowest=True)\n",
    "        df['Tenure_Group'] = pd.Categorical(tenure_group).codes\n",
    "        df['Is_New_Customer'] = (df['Tenure'] <= 1).astype(int)\n",
    "\n",
    "    if 'CreditScore' in df.columns:\n",
    "        credit_risk = pd.cut(df['CreditScore'], bins=[0, 400, 600, 750, 850, 1000], labels=['Very_High', 'High', 'Medium', 'Low', 'Very_Low'])\n",
    "        df['Credit_Risk'] = pd.Categorical(credit_risk).codes\n",
    "\n",
    "    if 'NumOfProducts' in df.columns:\n",
    "        df['Num_Products'] = df['NumOfProducts']\n",
    "        df['Has_Multiple_Products'] = (df['Num_Products'] > 1).astype(int)\n",
    "\n",
    "    if 'IsActiveMember' in df.columns and 'Tenure' in df.columns:\n",
    "        df['Activity_Tenure_Score'] = df['IsActiveMember'] * df['Tenure']\n",
    "\n",
    "    if 'Age' in df.columns and 'Num_Products' in df.columns:\n",
    "        df['Age_Product_Interaction'] = df['Age'] * df['Num_Products']\n",
    "\n",
    "    if 'Balance' in df.columns:\n",
    "        df['Zero_Balance'] = (df['Balance'] == 0).astype(int)\n",
    "        df['Low_Balance'] = (df['Balance'] < df['Balance'].quantile(0.25)).astype(int)\n",
    "\n",
    "    if 'Exited' in df.columns:\n",
    "        df['Exited'] = pd.to_numeric(df['Exited'], errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "    return df\n",
    "\n",
    "bank = preprocess_bank(bank_raw)\n",
    "bank.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0250a67b",
   "metadata": {},
   "source": [
    "## 4) Results and Model Performance\n",
    "\n",
    "The next cells train a consistent set of models per dataset and summarize performance in a table.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e05303",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_models(X: pd.DataFrame, y: pd.Series, random_state: int = 42, test_size: float = 0.2, title_prefix: str = ''):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state, stratify=y if y.nunique() == 2 else None)\n",
    "\n",
    "    models = {}\n",
    "    # SVM (scaled)\n",
    "    models['SVM (RBF)'] = Pipeline([('scaler', StandardScaler()), ('svm', SVC(kernel='rbf', probability=True, random_state=random_state))])\n",
    "\n",
    "    # Logistic Regression (scaled + simple CV over max_iter, matching your Streamlit pattern)\n",
    "    lr_pipe = Pipeline([('scaler', StandardScaler()), ('logreg', LogisticRegression())])\n",
    "    param_grid = {'logreg__max_iter': [500, 600, 700, 800, 900, 1000]}\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=random_state)\n",
    "    models['LogReg (CV)'] = GridSearchCV(lr_pipe, param_grid, cv=kf)\n",
    "\n",
    "    # Random Forest\n",
    "    models['RandomForest'] = RandomForestClassifier(random_state=random_state, n_estimators=200)\n",
    "\n",
    "    # Gradient Boosting\n",
    "    models['GradientBoosting'] = GradientBoostingClassifier(random_state=random_state)\n",
    "\n",
    "    rows = []\n",
    "    for name, model in models.items():\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        # proba for ROC-AUC when available\n",
    "        roc_auc = np.nan\n",
    "        if hasattr(model, 'predict_proba'):\n",
    "            y_proba = model.predict_proba(X_test)[:, 1]\n",
    "            fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "            roc_auc = auc(fpr, tpr)\n",
    "\n",
    "        rows.append({\n",
    "            'model': name,\n",
    "            'accuracy': float(model.score(X_test, y_test)),\n",
    "            'precision': float(precision_score(y_test, y_pred, zero_division=0)),\n",
    "            'recall': float(recall_score(y_test, y_pred, zero_division=0)),\n",
    "            'f1': float(f1_score(y_test, y_pred, zero_division=0)),\n",
    "            'roc_auc': float(roc_auc) if roc_auc == roc_auc else np.nan,\n",
    "        })\n",
    "\n",
    "        # Confusion matrix plot\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        plt.figure(figsize=(4.5, 3.5))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "        plt.title(f'{title_prefix}{name} — Confusion Matrix')\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('Actual')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    return pd.DataFrame(rows).sort_values(by=['f1', 'roc_auc'], ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e28c08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Telco training\n",
    "telco_target = 'Churn'\n",
    "X_telco = telco.drop(columns=[telco_target])\n",
    "y_telco = telco[telco_target]\n",
    "\n",
    "telco_results = evaluate_models(X_telco, y_telco, title_prefix='Telco: ')\n",
    "telco_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1569fba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bank training\n",
    "bank_target = 'Exited'\n",
    "X_bank = bank.drop(columns=[bank_target])\n",
    "y_bank = bank[bank_target]\n",
    "\n",
    "bank_results = evaluate_models(X_bank, y_bank, title_prefix='Bank: ')\n",
    "bank_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5919b5cc",
   "metadata": {},
   "source": [
    "### Interpretation (fill after running)\n",
    "\n",
    "- Best Telco model: _(fill from `telco_results`)_\n",
    "- Best Bank model: _(fill from `bank_results`)_\n",
    "\n",
    "Discuss trade-offs: interpretability (LogReg) vs performance (tree ensembles), and deployment considerations (latency, feature stability).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028df549",
   "metadata": {},
   "source": [
    "## 5) Screenshots of the Streamlit Interface\n",
    "\n",
    "Add 2–6 screenshots (recommended):\n",
    "\n",
    "1. Dataset tabs (Telco vs Bank)\n",
    "2. Telco model training results\n",
    "3. Telco prediction UI\n",
    "4. Bank model training results\n",
    "5. Bank prediction UI\n",
    "\n",
    "### How to capture\n",
    "\n",
    "- Run: `streamlit run streamlit.py`\n",
    "- Take screenshots and save them under `./screenshots/` (create the folder).\n",
    "\n",
    "### Embed in this report\n",
    "\n",
    "Replace the placeholder paths below once images exist.\n",
    "\n",
    "![Streamlit — Dataset Tabs](screenshots/01_tabs.png)\n",
    "\n",
    "![Streamlit — Telco Training](screenshots/02_telco_training.png)\n",
    "\n",
    "![Streamlit — Telco Prediction](screenshots/03_telco_prediction.png)\n",
    "\n",
    "![Streamlit — Bank Training](screenshots/04_bank_training.png)\n",
    "\n",
    "![Streamlit — Bank Prediction](screenshots/05_bank_prediction.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1993429",
   "metadata": {},
   "source": [
    "## 6) Conclusions and Recommendations\n",
    "\n",
    "**Conclusions (template)**\n",
    "\n",
    "- The two datasets differ significantly in feature composition: Telco is category-heavy with service attributes; Bank is numeric-heavy with customer/finance features.\n",
    "- Model performance is dataset-dependent; tree ensembles often perform strongly, while Logistic Regression provides interpretability.\n",
    "\n",
    "**Recommendations**\n",
    "\n",
    "- Monitor data drift: categorical distributions (Telco) and numeric ranges (Bank) can shift over time.\n",
    "- Add calibration / threshold tuning if the business cost of false positives/negatives is asymmetric.\n",
    "- Consider explaining predictions (feature importance / SHAP) before production rollout.\n",
    "- Validate fairness and bias across sensitive attributes where applicable (e.g., gender).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1305eb1b",
   "metadata": {},
   "source": [
    "## 7) Deployment Link (if applicable)\n",
    "\n",
    "- Streamlit deployment link: **_(paste your URL here)_**\n",
    "\n",
    "If not deployed yet, options include Streamlit Community Cloud, Hugging Face Spaces, or a small VM/container.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
